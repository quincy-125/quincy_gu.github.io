---
title: "PV 2021 - Using Progressive Context Encoders for Anomaly Detection in Digital
Pathology Images"
collection: talks
type: "Conference Poster Presentation"
permalink: /talks/2021-10-16-talk-1
venue: "2021 Pathology Visions Conference (PV 2021)"
date: 2021-10-16
location: "Las Vegas, NV"
---

Quincy Gu presented the research work titled ["Using Progressive Context Encoders for Anomaly Detection in Digital
Pathology Images"](https://www.biorxiv.org/content/10.1101/2021.07.02.450957v1.abstract) at [the 2021 Pathology Visions Conference (PV 2021)](https://digitalpathologyassociation.org/pathology-visions-agenda).

Details of this paper could be found in below:
* Title: Using Progressive Context Encoders for Anomaly Detection in Digital Pathology Images
* Abstract:
    * Whole slide imaging (WSI) is transforming the practice of pathology, converting a qualitative discipline into a quantitative one. However, one must exercise caution in interpreting algorithm assertions, particularly in pathology where an incorrect classification could have profound impacts on a patient, and rare classes exist that may not have been seen by the algorithm during training. 
    * A more robust approach would be to identify areas of an image for which the pathologist should concentrate their effort to make a final diagnosis. 
        * This anomaly detection strategy would be ideal for WSI, but given the extremely high resolution and large file sizes, such an approach is difficult. 
        * Here, we combine progressive generative adversarial networks with a flexible adversarial autoencoder architecture capable of learning the “normal distribution” of WSIs of normal skin tissue at extremely high resolution and demonstrate its anomaly detection performance. 
    * Our approach yielded pixel-level accuracy of 89% for identifying melanoma, suggesting that our label-free anomaly detection pipeline is a viable strategy for generating high quality annotations - without tedious manual segmentation by pathologists. The code is publicly available at our [GitHub P-CEAD repository](https://github.com/Steven-N-Hart/P-CEAD).